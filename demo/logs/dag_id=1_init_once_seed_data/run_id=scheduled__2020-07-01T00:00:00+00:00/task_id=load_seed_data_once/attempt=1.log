[2022-08-31 17:31:59,501] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-08-31 17:31:59,529] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-08-31 17:31:59,531] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-31 17:31:59,532] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-08-31 17:31:59,534] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-31 17:31:59,560] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): load_seed_data_once> on 2020-07-01 00:00:00+00:00
[2022-08-31 17:31:59,571] {standard_task_runner.py:52} INFO - Started process 162 to run task
[2022-08-31 17:31:59,580] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', '1_init_once_seed_data', 'load_seed_data_once', 'scheduled__2020-07-01T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/init.py', '--cfg-path', '/tmp/tmpbb_fmb7y', '--error-file', '/tmp/tmpknijgplx']
[2022-08-31 17:31:59,582] {standard_task_runner.py:80} INFO - Job 3: Subtask load_seed_data_once
[2022-08-31 17:31:59,780] {task_command.py:371} INFO - Running <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [running]> on host 4a8ffecbc2e6
[2022-08-31 17:31:59,880] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1471, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1575, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2232, in render_templates
    rendered_task = self.task.render_template_fields(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1188, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/abstractoperator.py", line 347, in _do_render_template_fields
    seen_oids,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/abstractoperator.py", line 403, in render_template
    return {key: self.render_template(value, context, jinja_env) for key, value in value.items()}
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/abstractoperator.py", line 403, in <dictcomp>
    return {key: self.render_template(value, context, jinja_env) for key, value in value.items()}
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/abstractoperator.py", line 390, in render_template
    return render_template_to_string(template, context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 296, in render_template_to_string
    return render_template(template, context, native=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 291, in render_template
    return "".join(nodes)
  File "<template>", line 12, in root
  File "/home/airflow/.local/lib/python3.7/site-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/context.py", line 100, in __getattr__
    self.var = Variable.get(key, deserialize_json=self._deserialize_json)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/variable.py", line 138, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable dbt_user does not exist'
[2022-08-31 17:31:59,909] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=1_init_once_seed_data, task_id=load_seed_data_once, execution_date=20200701T000000, start_date=20220831T173159, end_date=20220831T173159
[2022-08-31 17:31:59,940] {standard_task_runner.py:97} ERROR - Failed to execute job 3 for task load_seed_data_once ('Variable dbt_user does not exist'; 162)
[2022-08-31 17:31:59,998] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-08-31 17:32:00,084] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-31 22:35:31,777] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-08-31 22:35:31,827] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-08-31 22:35:31,829] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-31 22:35:31,831] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-08-31 22:35:31,833] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-31 22:35:31,873] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): load_seed_data_once> on 2020-07-01 00:00:00+00:00
[2022-08-31 22:35:31,893] {standard_task_runner.py:52} INFO - Started process 1591 to run task
[2022-08-31 22:35:31,908] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', '1_init_once_seed_data', 'load_seed_data_once', 'scheduled__2020-07-01T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/init.py', '--cfg-path', '/tmp/tmp9kfus_p9', '--error-file', '/tmp/tmpwst4rwgs']
[2022-08-31 22:35:31,923] {standard_task_runner.py:80} INFO - Job 4: Subtask load_seed_data_once
[2022-08-31 22:35:32,554] {task_command.py:371} INFO - Running <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [running]> on host 1b3d1bb2039d
[2022-08-31 22:35:34,930] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=1_init_once_seed_data
AIRFLOW_CTX_TASK_ID=load_seed_data_once
AIRFLOW_CTX_EXECUTION_DATE=2020-07-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-01T00:00:00+00:00
[2022-08-31 22:35:34,938] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-31 22:35:34,950] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'cd /dbt && dbt seed --profiles-dir .']
[2022-08-31 22:35:35,086] {subprocess.py:85} INFO - Output:
[2022-08-31 22:35:48,524] {subprocess.py:92} INFO - [0m22:35:48  Running with dbt=1.2.1
[2022-08-31 22:35:52,581] {subprocess.py:92} INFO - [0m22:35:52  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 506 macros, 0 operations, 3 seed files, 0 sources, 0 exposures, 0 metrics
[2022-08-31 22:35:52,628] {subprocess.py:92} INFO - [0m22:35:52
[2022-08-31 22:36:02,347] {subprocess.py:92} INFO - [0m22:36:02  Concurrency: 1 threads (target='dev')
[2022-08-31 22:36:02,352] {subprocess.py:92} INFO - [0m22:36:02
[2022-08-31 22:36:02,387] {subprocess.py:92} INFO - [0m22:36:02  1 of 3 START seed file PUBLIC.bookings_1 ....................................... [RUN]
[2022-08-31 22:36:08,310] {subprocess.py:92} INFO - [0m22:36:08  1 of 3 OK loaded seed file PUBLIC.bookings_1 ................................... [[32mINSERT 23[0m in 5.90s]
[2022-08-31 22:36:08,337] {subprocess.py:92} INFO - [0m22:36:08  2 of 3 START seed file PUBLIC.bookings_2 ....................................... [RUN]
[2022-08-31 22:36:10,794] {subprocess.py:92} INFO - [0m22:36:10  2 of 3 ERROR loading seed file PUBLIC.bookings_2 ............................... [[31mERROR[0m in 2.45s]
[2022-08-31 22:36:10,808] {subprocess.py:92} INFO - [0m22:36:10  3 of 3 START seed file PUBLIC.customers ........................................ [RUN]
[2022-08-31 22:36:14,559] {subprocess.py:92} INFO - [0m22:36:14  3 of 3 OK loaded seed file PUBLIC.customers .................................... [[32mINSERT 9[0m in 3.72s]
[2022-08-31 22:36:14,664] {subprocess.py:92} INFO - [0m22:36:14
[2022-08-31 22:36:14,676] {subprocess.py:92} INFO - [0m22:36:14  Finished running 3 seeds in 0 hours 0 minutes and 22.03 seconds (22.03s).
[2022-08-31 22:36:15,005] {subprocess.py:92} INFO - [0m22:36:15
[2022-08-31 22:36:15,012] {subprocess.py:92} INFO - [0m22:36:15  [31mCompleted with 1 error and 0 warnings:[0m
[2022-08-31 22:36:15,026] {subprocess.py:92} INFO - [0m22:36:15
[2022-08-31 22:36:15,036] {subprocess.py:92} INFO - [0m22:36:15  [33mDatabase Error in seed bookings_2 (seeds/bookings_2.csv)[0m
[2022-08-31 22:36:15,060] {subprocess.py:92} INFO - [0m22:36:15    002002 (42710): SQL compilation error:
[2022-08-31 22:36:15,080] {subprocess.py:92} INFO - [0m22:36:15    Object 'DEMO_DBT.PUBLIC.BOOKINGS_2' already exists.
[2022-08-31 22:36:15,086] {subprocess.py:92} INFO - [0m22:36:15
[2022-08-31 22:36:15,091] {subprocess.py:92} INFO - [0m22:36:15  Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[2022-08-31 22:36:16,932] {subprocess.py:96} INFO - Command exited with return code 1
[2022-08-31 22:36:16,975] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 195, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2022-08-31 22:36:16,990] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=1_init_once_seed_data, task_id=load_seed_data_once, execution_date=20200701T000000, start_date=20220831T223531, end_date=20220831T223616
[2022-08-31 22:36:17,019] {standard_task_runner.py:97} ERROR - Failed to execute job 4 for task load_seed_data_once (Bash command failed. The command returned a non-zero exit code 1.; 1591)
[2022-08-31 22:36:17,053] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-08-31 22:36:17,169] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-02 18:12:30,093] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-02 18:12:30,130] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-02 18:12:30,132] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-09-02 18:12:30,134] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-09-02 18:12:30,136] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-09-02 18:12:30,176] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): load_seed_data_once> on 2020-07-01 00:00:00+00:00
[2022-09-02 18:12:30,197] {standard_task_runner.py:52} INFO - Started process 269 to run task
[2022-09-02 18:12:30,231] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', '1_init_once_seed_data', 'load_seed_data_once', 'scheduled__2020-07-01T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/init.py', '--cfg-path', '/tmp/tmpnksjh8pm', '--error-file', '/tmp/tmpb9vpps1o']
[2022-09-02 18:12:30,235] {standard_task_runner.py:80} INFO - Job 3: Subtask load_seed_data_once
[2022-09-02 18:12:30,478] {task_command.py:371} INFO - Running <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [running]> on host 26ff35fadbf5
[2022-09-02 18:12:30,829] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=1_init_once_seed_data
AIRFLOW_CTX_TASK_ID=load_seed_data_once
AIRFLOW_CTX_EXECUTION_DATE=2020-07-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-01T00:00:00+00:00
[2022-09-02 18:12:30,835] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-09-02 18:12:30,839] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'cd /dbt && dbt seed --profiles-dir .']
[2022-09-02 18:12:30,888] {subprocess.py:85} INFO - Output:
[2022-09-02 18:12:57,809] {subprocess.py:92} INFO - [0m18:12:57  Running with dbt=1.2.1
[2022-09-02 18:13:00,653] {subprocess.py:92} INFO - [0m18:13:00  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 506 macros, 0 operations, 3 seed files, 0 sources, 0 exposures, 0 metrics
[2022-09-02 18:13:00,671] {subprocess.py:92} INFO - [0m18:13:00
[2022-09-02 18:13:10,957] {subprocess.py:92} INFO - [0m18:13:10  Concurrency: 1 threads (target='dev')
[2022-09-02 18:13:10,965] {subprocess.py:92} INFO - [0m18:13:10
[2022-09-02 18:13:11,006] {subprocess.py:92} INFO - [0m18:13:11  1 of 3 START seed file PUBLIC.bookings_1 ....................................... [RUN]
[2022-09-02 18:13:16,096] {subprocess.py:92} INFO - [0m18:13:16  1 of 3 OK loaded seed file PUBLIC.bookings_1 ................................... [[32mINSERT 23[0m in 5.05s]
[2022-09-02 18:13:16,128] {subprocess.py:92} INFO - [0m18:13:16  2 of 3 START seed file PUBLIC.bookings_2 ....................................... [RUN]
[2022-09-02 18:13:21,723] {subprocess.py:92} INFO - [0m18:13:21  2 of 3 OK loaded seed file PUBLIC.bookings_2 ................................... [[32mINSERT 16[0m in 5.58s]
[2022-09-02 18:13:21,749] {subprocess.py:92} INFO - [0m18:13:21  3 of 3 START seed file PUBLIC.customers ........................................ [RUN]
[2022-09-02 18:13:25,845] {subprocess.py:92} INFO - [0m18:13:25  3 of 3 OK loaded seed file PUBLIC.customers .................................... [[32mINSERT 9[0m in 4.09s]
[2022-09-02 18:13:25,899] {subprocess.py:92} INFO - [0m18:13:25
[2022-09-02 18:13:25,903] {subprocess.py:92} INFO - [0m18:13:25  Finished running 3 seeds in 0 hours 0 minutes and 25.22 seconds (25.22s).
[2022-09-02 18:13:26,010] {subprocess.py:92} INFO - [0m18:13:26
[2022-09-02 18:13:26,017] {subprocess.py:92} INFO - [0m18:13:26  [32mCompleted successfully[0m
[2022-09-02 18:13:26,028] {subprocess.py:92} INFO - [0m18:13:26
[2022-09-02 18:13:26,034] {subprocess.py:92} INFO - [0m18:13:26  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[2022-09-02 18:13:27,232] {subprocess.py:96} INFO - Command exited with return code 0
[2022-09-02 18:13:27,331] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=1_init_once_seed_data, task_id=load_seed_data_once, execution_date=20200701T000000, start_date=20220902T181230, end_date=20220902T181327
[2022-09-02 18:13:27,418] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-09-02 18:13:27,512] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-02 20:18:27,489] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-02 20:18:27,600] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-02 20:18:27,608] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-09-02 20:18:27,622] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-09-02 20:18:27,663] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-09-02 20:18:27,831] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): load_seed_data_once> on 2020-07-01 00:00:00+00:00
[2022-09-02 20:18:27,963] {standard_task_runner.py:52} INFO - Started process 683 to run task
[2022-09-02 20:18:28,024] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', '1_init_once_seed_data', 'load_seed_data_once', 'scheduled__2020-07-01T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/init.py', '--cfg-path', '/tmp/tmp0y5r9lc6', '--error-file', '/tmp/tmpbanphc83']
[2022-09-02 20:18:28,044] {standard_task_runner.py:80} INFO - Job 3: Subtask load_seed_data_once
[2022-09-02 20:18:29,202] {task_command.py:371} INFO - Running <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [running]> on host 46684d13e18c
[2022-09-02 20:18:31,398] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=1_init_once_seed_data
AIRFLOW_CTX_TASK_ID=load_seed_data_once
AIRFLOW_CTX_EXECUTION_DATE=2020-07-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-01T00:00:00+00:00
[2022-09-02 20:18:31,562] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-09-02 20:18:31,618] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'cd /dbt && dbt seed --profiles-dir .']
[2022-09-02 20:18:32,602] {subprocess.py:85} INFO - Output:
[2022-09-02 20:19:27,702] {subprocess.py:92} INFO - [0m20:19:27  Running with dbt=1.2.1
[2022-09-02 20:19:30,936] {subprocess.py:92} INFO - [0m20:19:30  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 506 macros, 0 operations, 3 seed files, 0 sources, 0 exposures, 0 metrics
[2022-09-02 20:19:30,997] {subprocess.py:92} INFO - [0m20:19:30
[2022-09-02 20:19:53,292] {subprocess.py:92} INFO - [0m20:19:53  Concurrency: 1 threads (target='dev')
[2022-09-02 20:19:53,318] {subprocess.py:92} INFO - [0m20:19:53
[2022-09-02 20:19:53,424] {subprocess.py:92} INFO - [0m20:19:53  1 of 3 START seed file PUBLIC.bookings_1 ....................................... [RUN]
[2022-09-02 20:20:00,600] {subprocess.py:92} INFO - [0m20:20:00  1 of 3 OK loaded seed file PUBLIC.bookings_1 ................................... [[32mINSERT 23[0m in 7.16s]
[2022-09-02 20:20:00,620] {subprocess.py:92} INFO - [0m20:20:00  2 of 3 START seed file PUBLIC.bookings_2 ....................................... [RUN]
[2022-09-02 20:20:06,081] {subprocess.py:92} INFO - [0m20:20:06  2 of 3 OK loaded seed file PUBLIC.bookings_2 ................................... [[32mINSERT 16[0m in 5.44s]
[2022-09-02 20:20:06,107] {subprocess.py:92} INFO - [0m20:20:06  3 of 3 START seed file PUBLIC.customers ........................................ [RUN]
[2022-09-02 20:20:11,656] {subprocess.py:92} INFO - [0m20:20:11  3 of 3 OK loaded seed file PUBLIC.customers .................................... [[32mINSERT 9[0m in 5.51s]
[2022-09-02 20:20:11,732] {subprocess.py:92} INFO - [0m20:20:11
[2022-09-02 20:20:11,741] {subprocess.py:92} INFO - [0m20:20:11  Finished running 3 seeds in 0 hours 0 minutes and 40.73 seconds (40.73s).
[2022-09-02 20:20:11,922] {subprocess.py:92} INFO - [0m20:20:11
[2022-09-02 20:20:11,928] {subprocess.py:92} INFO - [0m20:20:11  [32mCompleted successfully[0m
[2022-09-02 20:20:11,934] {subprocess.py:92} INFO - [0m20:20:11
[2022-09-02 20:20:11,940] {subprocess.py:92} INFO - [0m20:20:11  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[2022-09-02 20:20:15,619] {subprocess.py:96} INFO - Command exited with return code 0
[2022-09-02 20:20:16,117] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=1_init_once_seed_data, task_id=load_seed_data_once, execution_date=20200701T000000, start_date=20220902T201827, end_date=20220902T202016
[2022-09-02 20:20:16,526] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-09-02 20:20:16,942] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-28 17:20:38,244] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-28 17:20:38,258] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-28 17:20:38,259] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-09-28 17:20:38,260] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-09-28 17:20:38,261] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-09-28 17:20:38,277] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): load_seed_data_once> on 2020-07-01 00:00:00+00:00
[2022-09-28 17:20:38,282] {standard_task_runner.py:52} INFO - Started process 733 to run task
[2022-09-28 17:20:38,287] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', '1_init_once_seed_data', 'load_seed_data_once', 'scheduled__2020-07-01T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/init.py', '--cfg-path', '/tmp/tmp43kau0ho', '--error-file', '/tmp/tmpl6ogzd1f']
[2022-09-28 17:20:38,288] {standard_task_runner.py:80} INFO - Job 3: Subtask load_seed_data_once
[2022-09-28 17:20:38,373] {task_command.py:371} INFO - Running <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [running]> on host ec50df3269ef
[2022-09-28 17:20:38,508] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=1_init_once_seed_data
AIRFLOW_CTX_TASK_ID=load_seed_data_once
AIRFLOW_CTX_EXECUTION_DATE=2020-07-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-01T00:00:00+00:00
[2022-09-28 17:20:38,511] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-09-28 17:20:38,513] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'cd /dbt && dbt seed --profiles-dir .']
[2022-09-28 17:20:38,530] {subprocess.py:85} INFO - Output:
[2022-09-28 17:20:49,262] {subprocess.py:92} INFO - [0m17:20:49  Running with dbt=1.2.1
[2022-09-28 17:20:50,148] {subprocess.py:92} INFO - [0m17:20:50  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 506 macros, 0 operations, 3 seed files, 0 sources, 0 exposures, 0 metrics
[2022-09-28 17:20:50,168] {subprocess.py:92} INFO - [0m17:20:50
[2022-09-28 17:20:58,317] {subprocess.py:92} INFO - [0m17:20:58  Concurrency: 1 threads (target='dev')
[2022-09-28 17:20:58,320] {subprocess.py:92} INFO - [0m17:20:58
[2022-09-28 17:20:58,334] {subprocess.py:92} INFO - [0m17:20:58  1 of 3 START seed file PUBLIC.bookings_1 ....................................... [RUN]
[2022-09-28 17:21:00,072] {subprocess.py:92} INFO - [0m17:21:00  [31mUnhandled error while executing seed.dbt_airlfow.bookings_1[0m
[2022-09-28 17:21:00,074] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_1.csv'
[2022-09-28 17:21:00,080] {subprocess.py:92} INFO - [0m17:21:00  1 of 3 ERROR loading seed file PUBLIC.bookings_1 ............................... [[31mERROR[0m in 1.74s]
[2022-09-28 17:21:00,088] {subprocess.py:92} INFO - [0m17:21:00  2 of 3 START seed file PUBLIC.bookings_2 ....................................... [RUN]
[2022-09-28 17:21:01,900] {subprocess.py:92} INFO - [0m17:21:01  [31mUnhandled error while executing seed.dbt_airlfow.bookings_2[0m
[2022-09-28 17:21:01,901] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_2.csv'
[2022-09-28 17:21:01,915] {subprocess.py:92} INFO - [0m17:21:01  2 of 3 ERROR loading seed file PUBLIC.bookings_2 ............................... [[31mERROR[0m in 1.81s]
[2022-09-28 17:21:01,928] {subprocess.py:92} INFO - [0m17:21:01  3 of 3 START seed file PUBLIC.customers ........................................ [RUN]
[2022-09-28 17:21:03,773] {subprocess.py:92} INFO - [0m17:21:03  [31mUnhandled error while executing seed.dbt_airlfow.customers[0m
[2022-09-28 17:21:03,776] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/customers.csv'
[2022-09-28 17:21:03,785] {subprocess.py:92} INFO - [0m17:21:03  3 of 3 ERROR loading seed file PUBLIC.customers ................................ [[31mERROR[0m in 1.85s]
[2022-09-28 17:21:03,848] {subprocess.py:92} INFO - [0m17:21:03
[2022-09-28 17:21:03,851] {subprocess.py:92} INFO - [0m17:21:03  Finished running 3 seeds in 0 hours 0 minutes and 13.68 seconds (13.68s).
[2022-09-28 17:21:04,115] {subprocess.py:92} INFO - [0m17:21:04
[2022-09-28 17:21:04,119] {subprocess.py:92} INFO - [0m17:21:04  [31mCompleted with 3 errors and 0 warnings:[0m
[2022-09-28 17:21:04,122] {subprocess.py:92} INFO - [0m17:21:04
[2022-09-28 17:21:04,127] {subprocess.py:92} INFO - [0m17:21:04  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_1.csv'[0m
[2022-09-28 17:21:04,136] {subprocess.py:92} INFO - [0m17:21:04
[2022-09-28 17:21:04,139] {subprocess.py:92} INFO - [0m17:21:04  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_2.csv'[0m
[2022-09-28 17:21:04,144] {subprocess.py:92} INFO - [0m17:21:04
[2022-09-28 17:21:04,147] {subprocess.py:92} INFO - [0m17:21:04  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/customers.csv'[0m
[2022-09-28 17:21:04,152] {subprocess.py:92} INFO - [0m17:21:04
[2022-09-28 17:21:04,155] {subprocess.py:92} INFO - [0m17:21:04  Done. PASS=0 WARN=0 ERROR=3 SKIP=0 TOTAL=3
[2022-09-28 17:21:05,480] {subprocess.py:96} INFO - Command exited with return code 1
[2022-09-28 17:21:05,523] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 195, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2022-09-28 17:21:05,531] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=1_init_once_seed_data, task_id=load_seed_data_once, execution_date=20200701T000000, start_date=20220928T172038, end_date=20220928T172105
[2022-09-28 17:21:05,575] {standard_task_runner.py:97} ERROR - Failed to execute job 3 for task load_seed_data_once (Bash command failed. The command returned a non-zero exit code 1.; 733)
[2022-09-28 17:21:05,609] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-09-28 17:21:05,687] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-28 17:28:19,629] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-28 17:28:19,759] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-28 17:28:19,763] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-09-28 17:28:19,768] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-09-28 17:28:19,770] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-09-28 17:28:19,851] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): load_seed_data_once> on 2020-07-01 00:00:00+00:00
[2022-09-28 17:28:19,878] {standard_task_runner.py:52} INFO - Started process 1132 to run task
[2022-09-28 17:28:19,912] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', '1_init_once_seed_data', 'load_seed_data_once', 'scheduled__2020-07-01T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/init.py', '--cfg-path', '/tmp/tmp5vsefbju', '--error-file', '/tmp/tmp9a4x02yx']
[2022-09-28 17:28:19,916] {standard_task_runner.py:80} INFO - Job 4: Subtask load_seed_data_once
[2022-09-28 17:28:20,475] {task_command.py:371} INFO - Running <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [running]> on host ec50df3269ef
[2022-09-28 17:28:21,661] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=1_init_once_seed_data
AIRFLOW_CTX_TASK_ID=load_seed_data_once
AIRFLOW_CTX_EXECUTION_DATE=2020-07-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-01T00:00:00+00:00
[2022-09-28 17:28:21,672] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-09-28 17:28:21,675] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'cd /dbt && dbt seed --profiles-dir .']
[2022-09-28 17:28:21,713] {subprocess.py:85} INFO - Output:
[2022-09-28 17:28:31,188] {subprocess.py:92} INFO - [0m17:28:31  Running with dbt=1.2.1
[2022-09-28 17:28:32,124] {subprocess.py:92} INFO - [0m17:28:32  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 506 macros, 0 operations, 3 seed files, 0 sources, 0 exposures, 0 metrics
[2022-09-28 17:28:32,139] {subprocess.py:92} INFO - [0m17:28:32
[2022-09-28 17:28:39,040] {subprocess.py:92} INFO - [0m17:28:39  Concurrency: 1 threads (target='dev')
[2022-09-28 17:28:39,047] {subprocess.py:92} INFO - [0m17:28:39
[2022-09-28 17:28:39,056] {subprocess.py:92} INFO - [0m17:28:39  1 of 3 START seed file PUBLIC.bookings_1 ....................................... [RUN]
[2022-09-28 17:28:40,688] {subprocess.py:92} INFO - [0m17:28:40  [31mUnhandled error while executing seed.dbt_airlfow.bookings_1[0m
[2022-09-28 17:28:40,690] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_1.csv'
[2022-09-28 17:28:40,706] {subprocess.py:92} INFO - [0m17:28:40  1 of 3 ERROR loading seed file PUBLIC.bookings_1 ............................... [[31mERROR[0m in 1.64s]
[2022-09-28 17:28:40,725] {subprocess.py:92} INFO - [0m17:28:40  2 of 3 START seed file PUBLIC.bookings_2 ....................................... [RUN]
[2022-09-28 17:28:42,441] {subprocess.py:92} INFO - [0m17:28:42  [31mUnhandled error while executing seed.dbt_airlfow.bookings_2[0m
[2022-09-28 17:28:42,442] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_2.csv'
[2022-09-28 17:28:42,453] {subprocess.py:92} INFO - [0m17:28:42  2 of 3 ERROR loading seed file PUBLIC.bookings_2 ............................... [[31mERROR[0m in 1.72s]
[2022-09-28 17:28:42,465] {subprocess.py:92} INFO - [0m17:28:42  3 of 3 START seed file PUBLIC.customers ........................................ [RUN]
[2022-09-28 17:28:44,088] {subprocess.py:92} INFO - [0m17:28:44  [31mUnhandled error while executing seed.dbt_airlfow.customers[0m
[2022-09-28 17:28:44,090] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/customers.csv'
[2022-09-28 17:28:44,098] {subprocess.py:92} INFO - [0m17:28:44  3 of 3 ERROR loading seed file PUBLIC.customers ................................ [[31mERROR[0m in 1.63s]
[2022-09-28 17:28:44,134] {subprocess.py:92} INFO - [0m17:28:44
[2022-09-28 17:28:44,136] {subprocess.py:92} INFO - [0m17:28:44  Finished running 3 seeds in 0 hours 0 minutes and 11.99 seconds (11.99s).
[2022-09-28 17:28:44,224] {subprocess.py:92} INFO - [0m17:28:44
[2022-09-28 17:28:44,227] {subprocess.py:92} INFO - [0m17:28:44  [31mCompleted with 3 errors and 0 warnings:[0m
[2022-09-28 17:28:44,229] {subprocess.py:92} INFO - [0m17:28:44
[2022-09-28 17:28:44,232] {subprocess.py:92} INFO - [0m17:28:44  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_1.csv'[0m
[2022-09-28 17:28:44,234] {subprocess.py:92} INFO - [0m17:28:44
[2022-09-28 17:28:44,254] {subprocess.py:92} INFO - [0m17:28:44  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_2.csv'[0m
[2022-09-28 17:28:44,256] {subprocess.py:92} INFO - [0m17:28:44
[2022-09-28 17:28:44,258] {subprocess.py:92} INFO - [0m17:28:44  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/customers.csv'[0m
[2022-09-28 17:28:44,260] {subprocess.py:92} INFO - [0m17:28:44
[2022-09-28 17:28:44,262] {subprocess.py:92} INFO - [0m17:28:44  Done. PASS=0 WARN=0 ERROR=3 SKIP=0 TOTAL=3
[2022-09-28 17:28:45,026] {subprocess.py:96} INFO - Command exited with return code 1
[2022-09-28 17:28:45,045] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 195, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2022-09-28 17:28:45,050] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=1_init_once_seed_data, task_id=load_seed_data_once, execution_date=20200701T000000, start_date=20220928T172819, end_date=20220928T172845
[2022-09-28 17:28:45,067] {standard_task_runner.py:97} ERROR - Failed to execute job 4 for task load_seed_data_once (Bash command failed. The command returned a non-zero exit code 1.; 1132)
[2022-09-28 17:28:45,092] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-09-28 17:28:45,127] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-28 17:38:09,691] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-28 17:38:09,740] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [queued]>
[2022-09-28 17:38:09,742] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-09-28 17:38:09,745] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-09-28 17:38:09,747] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-09-28 17:38:09,810] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): load_seed_data_once> on 2020-07-01 00:00:00+00:00
[2022-09-28 17:38:09,830] {standard_task_runner.py:52} INFO - Started process 203 to run task
[2022-09-28 17:38:09,844] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', '1_init_once_seed_data', 'load_seed_data_once', 'scheduled__2020-07-01T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/init.py', '--cfg-path', '/tmp/tmpybuvx68q', '--error-file', '/tmp/tmp863g_88p']
[2022-09-28 17:38:09,846] {standard_task_runner.py:80} INFO - Job 4: Subtask load_seed_data_once
[2022-09-28 17:38:10,020] {task_command.py:371} INFO - Running <TaskInstance: 1_init_once_seed_data.load_seed_data_once scheduled__2020-07-01T00:00:00+00:00 [running]> on host 90f74b91582b
[2022-09-28 17:38:10,460] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=1_init_once_seed_data
AIRFLOW_CTX_TASK_ID=load_seed_data_once
AIRFLOW_CTX_EXECUTION_DATE=2020-07-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-07-01T00:00:00+00:00
[2022-09-28 17:38:10,468] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-09-28 17:38:10,475] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'cd /dbt && dbt seed --profiles-dir .']
[2022-09-28 17:38:10,502] {subprocess.py:85} INFO - Output:
[2022-09-28 17:38:32,332] {subprocess.py:92} INFO - [0m17:38:32  Running with dbt=1.2.1
[2022-09-28 17:38:33,494] {subprocess.py:92} INFO - [0m17:38:33  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 506 macros, 0 operations, 3 seed files, 0 sources, 0 exposures, 0 metrics
[2022-09-28 17:38:33,504] {subprocess.py:92} INFO - [0m17:38:33
[2022-09-28 17:38:42,529] {subprocess.py:92} INFO - [0m17:38:42  Concurrency: 1 threads (target='dev')
[2022-09-28 17:38:42,531] {subprocess.py:92} INFO - [0m17:38:42
[2022-09-28 17:38:42,546] {subprocess.py:92} INFO - [0m17:38:42  1 of 3 START seed file PUBLIC.bookings_1 ....................................... [RUN]
[2022-09-28 17:38:45,482] {subprocess.py:92} INFO - [0m17:38:45  [31mUnhandled error while executing seed.dbt_airlfow.bookings_1[0m
[2022-09-28 17:38:45,485] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_1.csv'
[2022-09-28 17:38:45,494] {subprocess.py:92} INFO - [0m17:38:45  1 of 3 ERROR loading seed file PUBLIC.bookings_1 ............................... [[31mERROR[0m in 2.94s]
[2022-09-28 17:38:45,503] {subprocess.py:92} INFO - [0m17:38:45  2 of 3 START seed file PUBLIC.bookings_2 ....................................... [RUN]
[2022-09-28 17:38:46,962] {subprocess.py:92} INFO - [0m17:38:46  [31mUnhandled error while executing seed.dbt_airlfow.bookings_2[0m
[2022-09-28 17:38:46,963] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_2.csv'
[2022-09-28 17:38:46,970] {subprocess.py:92} INFO - [0m17:38:46  2 of 3 ERROR loading seed file PUBLIC.bookings_2 ............................... [[31mERROR[0m in 1.46s]
[2022-09-28 17:38:46,976] {subprocess.py:92} INFO - [0m17:38:46  3 of 3 START seed file PUBLIC.customers ........................................ [RUN]
[2022-09-28 17:38:48,877] {subprocess.py:92} INFO - [0m17:38:48  [31mUnhandled error while executing seed.dbt_airlfow.customers[0m
[2022-09-28 17:38:48,878] {subprocess.py:92} INFO - [Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/customers.csv'
[2022-09-28 17:38:48,883] {subprocess.py:92} INFO - [0m17:38:48  3 of 3 ERROR loading seed file PUBLIC.customers ................................ [[31mERROR[0m in 1.90s]
[2022-09-28 17:38:48,928] {subprocess.py:92} INFO - [0m17:38:48
[2022-09-28 17:38:48,931] {subprocess.py:92} INFO - [0m17:38:48  Finished running 3 seeds in 0 hours 0 minutes and 15.42 seconds (15.42s).
[2022-09-28 17:38:49,021] {subprocess.py:92} INFO - [0m17:38:49
[2022-09-28 17:38:49,023] {subprocess.py:92} INFO - [0m17:38:49  [31mCompleted with 3 errors and 0 warnings:[0m
[2022-09-28 17:38:49,025] {subprocess.py:92} INFO - [0m17:38:49
[2022-09-28 17:38:49,027] {subprocess.py:92} INFO - [0m17:38:49  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_1.csv'[0m
[2022-09-28 17:38:49,029] {subprocess.py:92} INFO - [0m17:38:49
[2022-09-28 17:38:49,032] {subprocess.py:92} INFO - [0m17:38:49  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/bookings_2.csv'[0m
[2022-09-28 17:38:49,034] {subprocess.py:92} INFO - [0m17:38:49
[2022-09-28 17:38:49,036] {subprocess.py:92} INFO - [0m17:38:49  [33m[Errno 2] No such file or directory: '/Users/davidthomas/dbt+airlfow+demo/dbt_***_snowflake/demo/dbt/seeds/customers.csv'[0m
[2022-09-28 17:38:49,038] {subprocess.py:92} INFO - [0m17:38:49
[2022-09-28 17:38:49,041] {subprocess.py:92} INFO - [0m17:38:49  Done. PASS=0 WARN=0 ERROR=3 SKIP=0 TOTAL=3
[2022-09-28 17:38:49,877] {subprocess.py:96} INFO - Command exited with return code 1
[2022-09-28 17:38:49,920] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 195, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2022-09-28 17:38:49,932] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=1_init_once_seed_data, task_id=load_seed_data_once, execution_date=20200701T000000, start_date=20220928T173809, end_date=20220928T173849
[2022-09-28 17:38:49,963] {standard_task_runner.py:97} ERROR - Failed to execute job 4 for task load_seed_data_once (Bash command failed. The command returned a non-zero exit code 1.; 203)
[2022-09-28 17:38:50,004] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-09-28 17:38:50,071] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
